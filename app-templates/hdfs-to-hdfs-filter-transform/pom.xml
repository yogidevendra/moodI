<?xml version="1.0" encoding="UTF-8"?>
<!--
  ~ Copyright (c) 2012-2017 DataTorrent, Inc.
  ~ All Rights Reserved.
  ~ The use of this source code is governed by the Limited License located at
  ~ https://www.datatorrent.com/datatorrent-openview-software-license/
  -->

<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>
  <parent>
    <groupId>com.datatorrent.apps</groupId>
    <artifactId>moodi-app-templates</artifactId>
    <version>0.2.0-SNAPSHOT</version>
  </parent>
  <artifactId>hdfs-to-hdfs-filter-transform</artifactId>
  <name>HDFS to HDFS Filter Transform App</name>
  <version>0.11.0</version>
  <description>Ingest and backup hadoop HDFS data as lines from one cluster to another in a fault tolerant way.</description>
  <properties>
    <apex.apppackage.classpath>lib/*.jar</apex.apppackage.classpath>
    <apex.apppackage.tags>app-template, hdfs, filter, process, transform</apex.apppackage.tags>
    <apex.apppackage.longDescription>README.md</apex.apppackage.longDescription>
    <apex.apppackage.requiresRTSVersion>3.9.2</apex.apppackage.requiresRTSVersion>
  </properties>

  <dependencies>
    <dependency>
      <groupId>net.sf.supercsv</groupId>
      <artifactId>super-csv</artifactId>
      <version>2.4.0</version>
      <optional>true</optional>
    </dependency>
    <dependency>
      <groupId>org.codehaus.janino</groupId>
      <artifactId>janino</artifactId>
      <version>2.7.8</version>
    </dependency>
    <dependency>
      <groupId>com.github.fge</groupId>
      <artifactId>json-schema-validator</artifactId>
      <version>2.0.1</version>
      <optional>true</optional>
    </dependency>
  </dependencies>
</project>
